input {
  tcp {
    port => 5000
    type => syslog
  }
  udp {
    port => 5000
    type => syslog
  }
  beats {
    port => "5000"
    type => filebeat
  }

#  stdin { }
}

output {
  elasticsearch { host => "elasticsearch" }
  #stdout { codec => rubydebug }
}  

filter {
  if [type] == "syslog" {

# nc -w0 -u 192.168.33.10 5000 <<< '<134>Sep 27 01:20:32 haproxy[1]: 172.17.42.1:46563 [26/Sep/2015:21:43:31.697] https-in/1: SSL handshake failure'

# US: 56.42.42.42
# Paris: 86.217.118.136
# tokyo: 119.235.235.85

### Copy/paste ######################################

# FIRST PARSING CUT -----------------------------------------------------------------------------------------------
  #################################################
  ### haproxy logs via syslog
  #################################################    
  #   <141>Sep 23 12:47:33 haproxy[1]: Proxy https-in started.

  if [message] =~ "<\d+>\w+\s+\d+\s+\d+:\d+:\d+\s+\w+\[\d+\]: .*$" { 
      grok {
        match => { "message" => "%{SYSLOG5424PRI}%{CISCOTIMESTAMP} +(?:%{HOSTNAME:container_src}|-)\[\d\]: +%{GREEDYDATA:container_msg}" }
      }
  }  

  #################################################
  ### Container logs via docker log-driver
  #################################################
  #<27>2015-09-22T15:27:13Z vagrant-ubuntu-trusty-64 docker/20a591ad5b12[702]: Sep 22, 2015 3:27:13 PM org.elasticsearch.node.internal.InternalNode start
  #<30> Apr 27 12:41:10 elk-staging docker/kibana[850]: {"name":"Kibana","hostnam....  --> RFC:3164
  else {
    grok {
      match => { "message" => "%{SYSLOG5424PRI} +(?:%{CISCOTIMESTAMP:syslog_time}|-) +(?:%{HOSTNAME:container_host}|-) +(\w+/%{NOTSPACE:container_src}\[\d+\]): +%{GREEDYDATA:container_msg}" }
    }
    #date {
      #match => [ "syslog_time", "YYYY-MM-dd'T'HH:mm:ssZ" ]
      #target => "@timestamp"
      #locale => "en"
      #timezone => "UTC"
    #}
  }


# SECOND PARSING CUT ------------------------------------------------------------------------------------------------
  ############################################
  ### Trader log   
  ############################################
  # <27>2015-09-24T12:32:00+02:00 sbex-test docker/trader[29779]: [2015-09-24 12:32:00,067: INFO/MainProcess] Received task: exchange_rates.tasks.update_crypto_exchange_rates_task[07152fb3-0709-47e4-9afa-8f567dd7f913]
  # <27>2015-09-24T12:32:00+02:00 sbex-test docker/trader[29779]: [2015-09-11 22:06:03,194: INFO/Worker-2] [CC] [ORDER_PROCESSED] order 747 of 2.309304557551102600554048349 BTC in queue for sending to 1KQDeT9y93jUc4nJab3iwbp11ShqVs6k2E

  if [container_msg] =~ "^\[(\d+|-)+\s(\d+|:|,)+\s\w+\/\S+\].*" { 
    grok {
      match => { "container_msg" => "\[%{TIMESTAMP_ISO8601:trader_time}: %{WORD:level}/%{NOTSPACE:process}\](\s+\[%{NOTSPACE:app}\]|)(\s+\[%{NOTSPACE:status}\]|)\s+%{GREEDYDATA:trader_msg}$" }
    }
    mutate { 
      replace => [ "@source", "trader" ] 
    }
  }


  ############################################
  ### HaProxy log   
  ############################################
  # <134>Sep 23 14:52:13 haproxy[1]: 192.168.33.1:5504 [23/Sep/2015:14:52:13.758] https-in~ www_backend/fastcoin 34/0/0/2/42 200 19578 - - ---- 3/3/0/1/0 0/0 "GET /fonts/noto-700.woff HTTP/1.1"
  # <134>Sep 27 01:20:32 haproxy[1]: 172.17.42.1:46563 [26/Sep/2015:21:43:31.697] https-in/1: SSL handshake failure
  # http://www.haproxy.org/download/1.4/doc/configuration.txt

  #if [container_msg] =~ "^(?:[0-9]{1,3}\.){3}[0-9]{1,3}:\d+ \[\S+\] \S+\s+\w+\/\w+.*" { 
  if [container_msg] =~ "^(?:[0-9]{1,3}\.){3}[0-9]{1,3}:\d+ \[\S+\] \S+ \S+ .*" {
    grok {
      match => { "container_msg" => "%{IP:client_ip}:%{POSINT:client_port:int} %{SYSLOG5424SD:accept_date} %{NOTSPACE:frontend_name} %{NOTSPACE:backend_name}/%{NOTSPACE:server_name} %{INT:tq:int}\/%{INT:tw:int}/%{INT:tc:int}/%{INT:tr:int}/%{INT:tt:int} %{INT:response:int} %{INT:bytes_read:int} %{NOTSPACE:captured_request_cookie} %{NOTSPACE:captured_response_cookie} %{NOTSPACE:termination_state} %{INT:actconn:int}/%{INT:feconn:int}/%{INT:beconn:int}/%{INT:srv_conn:int}/%{INT:retries:int} %{INT:srv_queue:int}/%{INT:backend_queue:int} %{QUOTEDSTRING:http_request}" }
    }
    mutate { 
      replace => [ "@source", "haproxy" ] 
    }
  }

  ############################################
  ### Web (Nginx proxies or bakendtrader) logs 
  ############################################
  # <14>2015-07-20T17:19:16Z 456fe9ffba31 logging_logstash_1[1]: 56.42.42.42 - - [24/Aug/2015:12:11:36 +0000] "GET /api/doc/schema/currency?Authorization=ApiKey%20userame:apikey HTTP/1.1" 301 5 "http://preprod:8000/api/doc/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:39.0) Gecko/20100101 Firefox/39.0"

  if [container_msg] =~ "[?:[0-9]{1,3}\.){3}[0-9]{1,3}|-] [?:[0-9]{1,3}\.){3}[0-9]{1,3}|-] (\w+|-) \[.*\].*$" { 
    
    grok {
      match => { "container_msg" => "%{COMBINEDAPACHELOG}( %{QS:gzip_ratio}|)" }
    }

    geoip { source => "clientip" }
    useragent { source => agent }

    mutate { 
      replace => [ "@source", "web" ]
      rename => [ "timestamp" , "web_time" ] 
      convert => [ "response", "integer" ]
      convert => [ "bytes", "integer" ]

      # for useragent:
      rename => [ "name" , "browser_name" ]
      rename => [ "major" , "browser_maj" ]
      rename => [ "minor" , "browser_min" ] 
      convert => [ "browser_maj", "integer" ]
      convert => [ "browser_min", "integer" ]
    }
  }

  ############################################
  ### Api / python App log    
  ############################################
  # <14>2015-07-20T17:19:16Z 456fe9ffba31 logging_logstash_1[1]: INFO [API]  alexis@sbex.ch GET /api/v1/account/info/  200 72 (0.02 seconds) (2 SQL queries, 5.0 ms)

  if [container_msg] =~ "\w+ \[API\].*$" { 
    grok {
      match => { "container_msg" => "%{NOTSPACE:level} \[%{WORD}\]\s*(%{IP:remote_addr}|)\s*(%{NOTSPACE:user_email}|-)\s*(%{WORD:verb}|)\s*(%{NOTSPACE:request}|)\s*(\<%{WORD:sms_gw_response}\>|)\s*(\{%{GREEDYDATA:body}\}|null|None|)\s*(%{NUMBER:response:int}|)\s*(%{NUMBER:content_len:int}|)\s*(\(%{NUMBER:req_duration:float} %{WORD:req_unit}\)|)" }
    }
    mutate { 
      replace => [ "@source", "api" ] 
    }
  }

  ############################################
  ### Curator logs
  ############################################
  
  if "curator" in [container_src] {
    grok {
      match => { "container_msg" => "(%{TIMESTAMP_ISO8601:curator_time}|)( %{WORD:level}|)(\s*%{GREEDYDATA:curator_msg})" }
    }
    mutate { replace => [ "@source", "curator" ] }
  }

  ############################################
  ### ElasticSearch logs
  ############################################
  # <30>2015-09-23T10:06:04Z vagrant-ubuntu-trusty-64 docker/elasticsearch[863]: [2015-09-23 10:06:04,397][INFO ][cluster.metadata         ] [Nut] [logstash-2015.09.23] update_mapping [syslog] (dynamic)

  if "elastic" in [container_src] {
    multiline {
      # Correct 3sept2015
      # pattern => "^%{SYSLOG5424PRI}+(?:%{TIMESTAMP_ISO8601}|-) +(?:%{HOSTNAME}|-) +(?:%{NOTSPACE}\[\d\]|-): \[%{TIMESTAMP_ISO8601}\]"

      #pattern => "^%{SYSLOG5424PRI}+(?:%{TIMESTAMP_ISO8601}|-) +(?:%{HOSTNAME}|-) +(?:%{NOTSPACE}\[\d\]|-):"
      pattern => "(?m)(%{TIMESTAMP_ISO8601})\]+\s*+(\[%{WORD}:?\s*\])+\s*+(\[%{DATA}:?\s*\])+%{GREEDYDATA}$"
      negate => true
      #pattern => "^\n"
      what => "previous"
    }
    grok {
      match => { "container_msg" => "(?m)(%{TIMESTAMP_ISO8601:elastic_time})\]+\s*+(\[%{WORD:level}:?\s*\])+\s*+(\[%{DATA:service}:?\s*\])+\s*+(\[%{DATA:node}:?\s*\])+\s*+(\[%{DATA:index}:?\s*\]|)+%{GREEDYDATA:app_msg}" }
    }
    mutate { replace => [ "@source", "elasticsearch" ] }
  }

  ############################################
  ### Kibana logs
  ############################################

  # <30>2015-09-23T10:11:23Z vagrant-ubuntu-trusty-64 docker/kibana[863]: {"name":"Kibana","hostname":"52ae2cbb3ae3","pid":1,"level":30,"req":{"method":"POST","url":"/elasticsearch/_msearch?timeout=0&ignore_unavailable=true&preference=1443002938107","headers":{"host":"dev.local:5601","connection":"keep-alive","content-length":"809","accept":"application/json, text/plain, */*","origin":"http://dev.local:5601","user-agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.99 Safari/537.36","content-type":"application/json;charset=UTF-8","referer":"http://dev.local:5601/","accept-encoding":"gzip, deflate","accept-language":"en-US,en;q=0.8,fr;q=0.6","cookie":"__zlcmid=WreyUD6BelpUWM"},"remoteAddress":"192.168.33.1","remotePort":3759},"res":{"statusCode":200,"responseTime":177,"contentLength":339110},"msg":"POST /_msearch?timeout=0&ignore_unavailable=true&preference=1443002938107 200 - 177ms","time":"2015-09-23T10:11:23.747Z","v":0}

  if "kibana" in [container_src] {
    json { source => "container_msg" }
    geoip { source => "req.remoteAddress" }

    mutate { 
      replace => [ "@source", "kibana" ]
      rename => [ "time", "kibana_time" ] 
      convert => [ "level", "string" ]
    }
  }

  ############################################
  ### Logstash logs
  ############################################
  # <27>2015-09-23T09:57:25Z vagrant-ubuntu-trusty-64 docker/logstash[863]: Sep 23, 2015 9:57:25 AM org.elasticsearch.cluster.service.InternalClusterService$UpdateTask run

  if "logstash" in [container_src] {
    grok {
      patterns_dir => "/opt/logstash/conf.d/patterns"
      match => { "container_msg" => "(%{DATESTAMP_12HOUR:logstash_time} |)(%{LOGLEVEL:level}: |)%{GREEDYDATA:app_msg}" }
    }
    date {
      match => [ "logstash_time", "MMM dd, YYYY hh:mm:ss aa", "MMM  d, YYYY hh:mm:ss aa" ]
      target => "logstash_time"
    }
    mutate { replace => [ "@source", "logstash" ] }
  }

### END Copy/paste ######################################

  } # END Loop if [type] == "syslog" {
} #END filter

